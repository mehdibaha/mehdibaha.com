+++
title = "Can Most Research Findings Be Actually False?"
tags = [
    "science",
    "philosophy",
]
date = "2017-10-04"
+++

## Most research is actually false

Since most research is known for its objectivity, we may assume that research has to be blindly trusted. After all, isn't research the best way to prove or deny a claimed theory? And as research findings are mostly backed by seemingly hard evidence, it seems hard to challenge this fact.

In his paper[1], researcher John P. A. Ioannidis tries to prove the contrary by way of logical demonstration.

The author starts by debunking the myth which consists in correlating alleged *true* research discoveries with their formal statistical significance (p-value less than 0.05).

Then, by showing that this statistical significance is actually not correlated to PPV; a.k.a positive predictive value, or in other words, the number of true research findings amongst all research findings, the author proves a number of corrolaries.

A first one would be that the smaller the effect research areas have on the population, the less likely they are to be true. Since findings in "niche" research areas are harder to debunk, naturally, less people are actively working on demonstrating they're false.

According to the author, the number of different analytical methods used to prove findings in a research area also play a role. As a matter of fact, if the number of different scientific methods is high, research findings are less likely to be true.

Another unintuitive discovery is that findings in "hot" scientific fields are not necessarily true. The contrary is actually more prevalent, by way of the Proteus phenomen which results in producing papers countering each other in an alternate way rather than producing original (and true!) research findings.

Finally, the author argues by using a genome study as an example, that researchers can manage to find statistical significance in their findings by way of optimizing the p-metric. So by choosing for example subgroups yielding a p-metric lesser than 0.05, they can easily reach statistical significance[2].

## Research is a measure of bias

The author proceeds in explaining how findings can actually reflect bias in the research world.

He explains that in the case of a research field where there is no true findings (e.g attempting to find correlations between the speed of the wind and lottery outcomes), research tends to favor one outcome over the other only because of bias: simply because no other *hard* factor is present.

We can extend this thought experiment to research areas where there is only very few *true* research findings and conclude that prevailing biases play a big role in the effect of research findings.

The author also ends his argument by warning us that while most researchers claim their field isn't a null field, the analysis of bias is still extremely useful in research areas where similar methods and technologies are used.

## Conclusion

While the author's findings may seem fairly pessimistic about the current state of research, the author suggests a few guidelines to improve it (even if we know there's no actual way of verifying whether most research is true or not).

According to the author, we should therefore look at research with larger scrutiny, search for large-scale evidence in scientific findings and try as much as possible to avoid false signals like marketing promotion associated to a new finding.

*This article is part of a series of essays around science and philosophy (course assignments for KTH @ Fall 2018).*

### References

[1] Why Most Published Research Findings Are False - John P. A. Ioannidis

[2] https://www.vox.com/science-and-health/2017/7/31/16021654/p-values-statistical-significance-redefine-0005
